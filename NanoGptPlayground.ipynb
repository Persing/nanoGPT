{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install tiktoken\n",
    "!pip install wandb\n",
    "!pip install tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_json('data/mtg_char/default-cards-20230313210730.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# peek at the data\n",
    "print(data.shape)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter out cards that are not in english\n",
    "data = data[data['lang'] == 'en']\n",
    "print(data.shape)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keep only normal cards\n",
    "data = data[data['layout'] == 'normal']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove cards with duplicate names\n",
    "data = data.drop_duplicates(subset=['name'])\n",
    "print(data.shape)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now that we dont have any other languages, we can drop the lang column\n",
    "data = data.drop(columns=['lang'])\n",
    "print(data.shape)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.drop(columns=['mtgo_id', 'mtgo_foil_id', 'arena_id', 'tcgplayer_id', 'cardmarket_id', 'legalities', 'games', 'reserved', 'foil', 'nonfoil', 'finishes', 'oversized', 'promo', 'reprint', 'variation', 'artist', 'artist_ids', 'illustration_id', 'border_color', 'booster', 'story_spotlight', 'edhrec_rank', 'penny_rank','prices', 'promo_types', 'arena_id', 'preview', 'security_stamp', 'tcgplayer_etched_id', 'variation_of','released_at', 'set_id','set', 'set_uri', 'set_search_uri', 'scryfall_set_uri', 'rulings_uri', 'prints_search_uri', 'card_back_id', 'frame', 'related_uris'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.drop(columns=['object', 'id', 'oracle_id', 'uri', 'scryfall_uri', 'layout', 'highres_image', 'image_status', 'printed_name', 'card_faces', 'attraction_lights', 'color_indicator', 'color_indicator', 'life_modifier', 'hand_modifier', 'printed_type_line', 'printed_text', 'content_warning', 'flavor_name'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.drop(columns=['full_art', 'textless', 'all_parts', 'produced_mana', 'watermark', 'loyalty', 'frame_effects', 'digital', 'cmc' ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = data.drop(columns=['keywords', 'collector_number', 'colors', 'color_identity'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['oracle_text'] = data.apply(lambda x: x['oracle_text'].replace(x['name'], '<card_name>'), axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build a string representation of each card to be saved out as a text file.\n",
    "# Card data will be represented as a string with the following format:\n",
    "# \"<|endoftext|>{card_name} | ?{mana_cost} | {type_line} | {rarity} | ?{oracle_text} | ?{flavor_text} | ?{power} | ?{toughness}<|endoftext|>\"\n",
    "# The ? indicates that the field may be empty.\n",
    "\n",
    "# start of text token\n",
    "sot = \"<|startoftext|>\"\n",
    "# end of text token\n",
    "eot = \"<|endoftext|>\"\n",
    "# pad token\n",
    "pad = \"<|pad|>\"\n",
    "\n",
    "card_data = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    card_data.append(f\" {eot} {row['name']} | {row['mana_cost']} | {row['type_line']} | {row['rarity']} | {row['oracle_text']} | {row['flavor_text']} | {row['power']} | {row['toughness']} {eot} \\n\")\n",
    "\n",
    "# sample the first 10 cards\n",
    "card_data[:10]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove all new line characters from the data\n",
    "card_data = [card.replace('\\n', ' ') for card in card_data]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the card data to a text file\n",
    "with open('data/mtg_char/mtg_card_data.txt', 'w') as f:\n",
    "    f.write(''.join(card_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# write out the dataframe to a json file\n",
    "data.to_json('data/mtg_char/mtg_card_data.json', orient='records', lines=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data into a dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dataset from the text file\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('text', data_files='data/mtg_char/mtg_card_data.json')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sample the first 10 cards\n",
    "dataset['train'][:1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['train'].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', max_length=1024 , padding='max_length', pad_to_max_length=True, add_prefix_space=True, truncation=True, bos_token='<|endoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>', return_tensors='pt', mask_token='<|mask|>')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tokenize the dataset\n",
    "tokenized_dataset = dataset.map(lambda examples: tokenizer(examples['text'], add_special_tokens=True ), batched=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenized_dataset.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split the dataset into train and validation\n",
    "tokenized_dataset = tokenized_dataset['train'].train_test_split(test_size=0.2)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a model\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2-medium')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the model\n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=1,              # total # of training epochs\n",
    "    per_device_train_batch_size=1,  # batch size per device during training\n",
    "    per_device_eval_batch_size=1,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=tokenized_dataset['train'],         # training dataset\n",
    "    eval_dataset=tokenized_dataset['test'],           # evaluation dataset\n",
    "    data_collator=data_collator,         # data collator\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers.integrations import WandbCallback\n",
    "\n",
    "# disable the wandb logger\n",
    "trainer.remove_callback(WandbCallback)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# peek into the tokenized dataset\n",
    "tokenized_dataset['train'][0]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dataset from the text file\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('text', data_files='data/mtg_char/mtg_card_data.json')\n",
    "\n",
    "# sample the first 10 cards\n",
    "dataset['train'][:1]\n",
    "\n",
    "dataset['train'].shape\n",
    "# create a tokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', max_length=1024, padding='max_length', pad_to_max_length=True, add_prefix_space=True, truncation=True, bos_token='', eos_token='', pad_token='<pad>', return_tensors='pt', mask_token='')\n",
    "\n",
    "\n",
    "# tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], add_special_tokens=True, padding='max_length', truncation=True, max_length=1024)\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_dataset.shape\n",
    "# split the dataset into train and validation\n",
    "tokenized_dataset = tokenized_dataset['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "# create a model\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2-medium')\n",
    "\n",
    "# train the model\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # output directory\n",
    "    num_train_epochs=1,  # total # of training epochs\n",
    "    per_device_train_batch_size=1,  # batch size per device during training\n",
    "    per_device_eval_batch_size=1,  # batch size for evaluation\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir='./logs',  # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=tokenized_dataset['train'],  # training dataset\n",
    "    eval_dataset=tokenized_dataset['test'],  # evaluation dataset\n",
    "    data_collator=data_collator,  # data collator\n",
    ")\n",
    "\n",
    "from transformers.integrations import WandbCallback\n",
    "\n",
    "# disable the wandb logger\n",
    "trainer.remove_callback(WandbCallback)\n",
    "\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dataset from the text file\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('text', data_files='data/mtg_char/mtg_card_data.json')\n",
    "\n",
    "# create a tokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', max_length=1024 , padding='max_length', pad_to_max_length=True, add_prefix_space=True, truncation=True, bos_token='', eos_token='', pad_token='<pad>', return_tensors='pt', mask_token='')\n",
    "\n",
    "# tokenize the dataset\n",
    "tokenized_dataset = dataset.map(lambda examples: tokenizer(examples['text'], add_special_tokens=True ), batched=True)\n",
    "\n",
    "# split the dataset into train and validation\n",
    "tokenized_dataset = tokenized_dataset['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "# create a model\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2-medium')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# train the model\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "from transformers.integrations import WandbCallback\n",
    "\n",
    "# disable the wandb logger\n",
    "trainer.remove_callback(WandbCallback)\n",
    "\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evalute the model\n",
    "trainer.evaluate()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the model\n",
    "trainer.save_model('mtg_card_model')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#sample the model output\n",
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='mtg_card_model', tokenizer='gpt2')\n",
    "unmasker('')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#generate the model output\n",
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model='mtg_card_model', tokenizer='gpt2', max_length=1024, do_sample=True, top_k=50, top_p=0.95, num_return_sequences=1, repetition_penalty=1.0, temperature=1.0, no_repeat_ngram_size=2, bad_words_ids=None, pad_token_id=50256, length_penalty=1.0, num_beams=1, early_stopping=False, use_cache=True, num_beam_groups=1, diversity_penalty=0.0, prefix_allowed_tokens_fn=None, output_attentions=None, output_hidden_states=None, output_scores=None, return_dict_in_generate=None, forced_bos_token_id=None, forced_eos_token_id=None, remove_invalid_values=None, return_dict=None)\n",
    "generator('')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sample the first element of the dataset\n",
    "\n",
    "dataset['train'][0]\n",
    "dataset.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# create a function to get the base64 encoded art_crop image\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "def get_image_url(card):\n",
    "    return card['image_uris']['art_crop']\n",
    "\n",
    "#create a function to get the image from the url in base64 encoding\n",
    "def get_image_base64(card):\n",
    "    url = get_image_url(card)\n",
    "    response = requests.get(url)\n",
    "    return base64.b64encode(response.content).decode('utf-8')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try the function out on the first row of data\n",
    "get_image_base64(data.iloc[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test the image classifier api\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.post(\"https://persing-clip-interrogator.hf.space/run/clipit\", json={\n",
    "  \"data\": [\n",
    "    \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAACklEQVR4nGMAAQAABQABDQottAAAAABJRU5ErkJggg==\",\n",
    "    \"ViT-L (best for Stable Diffusion 1.*)\",\n",
    "    \"best\",\n",
    "]}).json()\n",
    "\n",
    "description = response[\"data\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "description"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a function to get the description from the image\n",
    "\n",
    "def get_description(image_base64):\n",
    "    response = requests.post(\"https://persing-clip-interrogator.hf.space/run/clipit\", json={\n",
    "        \"data\": [\n",
    "            \"data:image/png;base64,\" + image_base64 ,\n",
    "            \"ViT-L (best for Stable Diffusion 1.*)\",\n",
    "            \"fast\",\n",
    "        ]}).json()\n",
    "    return response[\"data\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test the function\n",
    "get_description(get_image_base64(data.iloc[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# add a column to the dataset with the art_description for the first 10 rows\n",
    "data['art_description'] = data.iloc[:1].apply(lambda row: get_description(get_image_base64(row)), axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# time how long it takes to get the descriptions for the first 5 rows\n",
    "import time\n",
    "start = time.time()\n",
    "data['art_description'] = data.iloc[:5].apply(lambda row: get_description(get_image_base64(row)), axis=1)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the size of the dataset\n",
    "data.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 135 seconds time the data size, then divide by 60*60 to get the hours\n",
    "135*25438/(60*60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# that was the time before I changed the api call to fast from best\n",
    "12.5*25438/(60*60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# thats still way too long, maybe reduce the resolution of the images\n",
    "\n",
    "\n",
    "# Check the current size of the images\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "url = get_image_url(data.iloc[0])\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img.size\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# I wonder how acurate the image classifier is with the lower resolution images\n",
    "# Let's try it with 256x256 images\n",
    "\n",
    "# resize the image\n",
    "img = img.resize((256, 256))\n",
    "img.size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert the image to base64\n",
    "base64_image = base64.b64encode(BytesIO(response.content).getvalue()).decode('utf-8')\n",
    "\n",
    "# get the description\n",
    "description = get_description(base64_image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "description"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's redefine the get_image_base64 function to resize the image to 256x256\n",
    "\n",
    "\n",
    "# def get_image_base64(card):\n",
    "#     url = get_image_url(card)\n",
    "#     response = requests.get(url)\n",
    "#     img = Image.open(BytesIO(response.content))\n",
    "#     img = img.resize((256, 256))\n",
    "#     img_byte_arr = BytesIO()\n",
    "#     img.save(img_byte_arr, format='PNG')\n",
    "#     img_byte_arr = img_byte_arr.getvalue()\n",
    "#     return base64.b64encode(BytesIO(img_byte_arr).getvalue()).decode('utf-8')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# It looks like that still works, so let's try timing the first 5 rows again but this time resize the images to 256x256\n",
    "start = time.time()\n",
    "data['art_description'] = data.iloc[:5].apply(lambda row: get_description(get_image_base64(row)), axis=1)\n",
    "end = time.time()\n",
    "print(end - start)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# that actually took longer. I wonder if it's because the images are being resized. Let's try it again but this time resize the images before the api call\n",
    "\n",
    "# here we will resize the images before the api call and store the base64 encoded image in the art_description column\n",
    "data['art_description'] = data.iloc[:5].apply(lambda row: get_image_base64(row), axis=1)\n",
    "\n",
    "# now we will get the description from the base64 encoded image and time it\n",
    "start = time.time()\n",
    "data['art_description'] = data.iloc[:5].apply(lambda row: get_description(row['art_description']), axis=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# That still took longer, I guess the model is already downsizing the images. So there is no point in downsizing the images before the api call"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# let's see if all rows have a value for art_crop\n",
    "data['image_uris'].isnull().sum()\n",
    "# 0 rows have a null value for image_uris so now lets see if all of the image uris have an art_crop\n",
    "data['image_uris'].apply(lambda x: x['art_crop'] if x is not None else None).isnull().sum()\n",
    "\n",
    "# data['image_uris'][0]['art_crop']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# looks like we cant cut down on the number of descriptions we need to get maybe we can run this locally to avoid some costs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickpersing/PycharmProjects/nanoGPT/nanoGPT/venv/lib/python3.9/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/Users/nickpersing/PycharmProjects/nanoGPT/nanoGPT/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'a soccer game with a player jumping to catch the ball '}]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "image_to_text = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "image_to_text(\"https://ankur3107.github.io/assets/images/image-captioning-example.png\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickpersing/PycharmProjects/nanoGPT/nanoGPT/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'generated_text': 'a painting of a bird with a fish in its mouth '}]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try it on the first row of the dataset\n",
    "image_to_text(get_image_url(new_data.iloc[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickpersing/PycharmProjects/nanoGPT/nanoGPT/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.392888069152832\n"
     ]
    }
   ],
   "source": [
    "# let's try it on the first 5 rows of the dataset and time it\n",
    "import time\n",
    "start = time.time()\n",
    "new_data['art_description'] = new_data.iloc[:5].apply(lambda row: image_to_text(get_image_url(row))[0]['generated_text'], axis=1)\n",
    "end = time.time()\n",
    "print(end - start)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "0       a painting of a bird with a fish in its mouth \n1        a woman in a costume is posing for a picture \n3       a painting of a woman in a bikini with a fish \n4        a river with a bunch of birds flying over it \n5    two women in a park with a painting of a man a...\nName: art_description, dtype: object"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['art_description'].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "'a painting of a bird with a fish in its mouth '"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets isolate the first row and see what the model is returning\n",
    "new_data.iloc[0]['art_description']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This model seems to create an issue with microsoft threat protection so I am restricted to running on my laptop at the moment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# lets load everything and see how far it gets in the night"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickpersing/PycharmProjects/nanoGPT/nanoGPT/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632.1368598937988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickpersing/PycharmProjects/nanoGPT/nanoGPT/venv/lib/python3.9/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# we want to batch the job up into 100 rows at a time, retreive the descriptions from the pipeline and store them in the 'art_description' column of the dataframe. After each batch we will save the dataframe to a json file so we can pick up where we left off if the job is interrupted.\n",
    "\n",
    "for i in range(0, new_data.shape[0], 1000):\n",
    "    start = time.time()\n",
    "    new_data['art_description'] = new_data.iloc[i:i+1000].apply(lambda row: image_to_text(get_image_url(row))[0]['generated_text'], axis=1)\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    new_data.to_json(f'./data/{i}.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# It ran overnight. I should have put a timer in there to see how long it took to run.\n",
    "# looking at file creation times it looks like it ran from 10:00pm to 2:30am so 4.5 hours. Not too bad considering it was running on my laptop.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# The jupyter notebook seems to be having some issues displaying tables. so let's test loading in the data from the json files and compare it to the data variable\n",
    "import pandas as pd\n",
    "\n",
    "new_data = pd.read_json('./data/25400.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now we can compare the dataframes\n",
    "data.equals(new_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# looks like the dataframes are the same. So now I can confidently restart the kernel and load in the data from the json files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(25438, 13)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets peek at the first 5 rows of the art_description column\n",
    "new_data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0    None\n1    None\n3    None\n4    None\n5    None\nName: art_description, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['art_description'].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
